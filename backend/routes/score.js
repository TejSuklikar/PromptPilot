// backend/routes/score.js

const express = require("express");
const { Anthropic } = require("@anthropic-ai/sdk");

// 1Ô∏è‚É£ Instantiate the Claude client with your API key
const claude = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY
});

const router = express.Router();

router.post("/", async (req, res) => {
  try {
    // 2Ô∏è‚É£ Extract the user's prompt from the request body
    const { prompt } = req.body;

    // 3Ô∏è‚É£ Build a super-detailed system instruction
    const systemMessage = `
You are PromptPilot‚Äôs senior/expert/master AI prompt evaluation engine. Follow these instructions exactly:

1. **Overall Score**
   ‚Ä¢ On a scale of 1‚Äì10 (1 = unusable, 10 = perfect), rate the prompt for its likelihood to produce a correct, detailed, and focused response from a modern LLM.

2. **Category Tags**
   ‚Ä¢ Identify the prompt‚Äôs type by selecting one or more of:
     ["question", "instruction", "creative_writing", "code_generation", "translation", "summary", "analysis", "other"]

3. **Detailed Breakdown**
   For each criterion, assign a sub-score (1‚Äì10) and a concise comment (5‚Äì12 words):
   - Clarity: how clearly the request is phrased  
   - Specificity: how well it defines scope, constraints, or format  
   - Context: whether it includes necessary background or examples  
   - Brevity: how concise and focused the language is  
   - Feasibility: how likely an LLM can fulfill it without extra instructions  
   - Creativity: how much it encourages novel or original output  

4. **Success Prediction**
   ‚Ä¢ Predict the probability (0‚Äì100%) this prompt will succeed on each model:
     - GPT-o3  
     - Claude-4 Sonnet  
     - Gemini 1.5 Pro  

5. **Overall Comment**
   ‚Ä¢ Summarize in 1‚Äì2 sentences the prompt‚Äôs main strength and biggest weakness.  

6. **Improved Rewrite**
   ‚Ä¢ Provide a single-paragraph, fully-polished rewrite that addresses all identified issues.  

7. **Output Format**
   Respond in valid JSON ONLY, with exactly these keys (no extra text):

\`\`\`json
{
  "overall_score": <number 1‚Äì10>,
  "tags": [ "question", ‚Ä¶ ],
  "breakdown": {
    "clarity":    { "score": <1‚Äì10>, "comment": "<‚Ä¶>" },
    "specificity":{ "score": <1‚Äì10>, "comment": "<‚Ä¶>" },
    "context":    { "score": <1‚Äì10>, "comment": "<‚Ä¶>" },
    "brevity":    { "score": <1‚Äì10>, "comment": "<‚Ä¶>" },
    "feasibility":{ "score": <1‚Äì10>, "comment": "<‚Ä¶>" },
    "creativity": { "score": <1‚Äì10>, "comment": "<‚Ä¶>" }
  },
  "success_prediction": {
    "GPT-o3":    "<0‚Äì100%>",
    "Claude-4 Sonnet": "<0‚Äì100%>",
    "Gemini 1.5 Pro":  "<0‚Äì100%>"
  },
  "overall_comment": "<‚Ä¶>",
  "rewrite": "<‚Ä¶improved prompt‚Ä¶>"
}
\`\`\`

User Prompt:
"""${prompt}"""
`;

    // 4Ô∏è‚É£ Call Claude's Messages API
    const response = await claude.messages.create({
      model:      "claude-2",     // supported model
      system:     systemMessage,  // top-level instruction
      messages:   [{ role: "user", content: prompt }],
      max_tokens: 600,
      temperature: 0.0
    });

    // 5Ô∏è‚É£ Inspect the raw response
    console.log("ü™µ Claude raw response:", response);

    // 6Ô∏è‚É£ Extract the generated text, handling various formats
    let text = null;

    // a) Completions-style
    if (typeof response.completion === "string") {
      text = response.completion;
    }
    // b) Chat-style (messages array)
    else if (
      Array.isArray(response.messages) &&
      typeof response.messages[0]?.content === "string"
    ) {
      text = response.messages[0].content;
    }
    // c) Chunked content array
    else if (
      Array.isArray(response.content) &&
      response.content.every((c) => typeof c.text === "string")
    ) {
      text = response.content.map((c) => c.text).join("");
    }

    if (!text) {
      console.error("‚ö†Ô∏è Couldn't find any text in Claude response");
      return res.status(500).json({ error: "No AI output found" });
    }

    // 7Ô∏è‚É£ Extract the JSON block between ```json ... ```
    const match = text.match(/```json\s*([\s\S]*?)\s*```/);
    if (!match) {
      console.error("‚ö†Ô∏è No JSON fence found in Claude response:", text);
      return res.status(500).json({ error: "AI response missing JSON block" });
    }
    const jsonPayload = match[1];

    // 8Ô∏è‚É£ Parse and return the JSON
    let result;
    try {
      result = JSON.parse(jsonPayload);
    } catch (err) {
      console.error("üì¶ Failed to parse JSON:", err, jsonPayload);
      return res.status(500).json({ error: "AI JSON parse error" });
    }

    return res.json(result);

  } catch (err) {
    console.error("‚ùå Scoring error:", err);
    return res.status(500).json({ error: "Failed to score prompt" });
  }
});

module.exports = router;
